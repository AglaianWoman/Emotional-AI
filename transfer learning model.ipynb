{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "#read in data\n",
    "df = pd.read_excel('data/fer2013.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import ceil \n",
    "\n",
    "#set up train/test indices\n",
    "indices = list(range(len(df[df['Usage'] == 'Training'])))\n",
    "np.random.shuffle(indices)\n",
    "train_indices = indices[ceil(len(indices)/5):]\n",
    "valid_indices = indices[:ceil(len(indices)/5)]\n",
    "labels = df.emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#split train/test/validation sets, and do one hot encoding on labels\n",
    "one_hot_labels = keras.utils.to_categorical(df.emotion, num_classes=len(df.emotion.unique()))\n",
    "test_labels = one_hot_labels[~df.index.isin(indices)]\n",
    "train_labels = one_hot_labels[train_indices]\n",
    "valid_labels = one_hot_labels[valid_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#converts gray scale images to RGB to make it appropriate for keras preprocessing tools\n",
    "def to_rgb1a(im):\n",
    "    # Convert to RGB\n",
    "    w, h = im.shape\n",
    "    ret = np.empty((w, h, 3), dtype=np.float16)\n",
    "    ret[:, :, 2] =  ret[:, :, 1] =  ret[:, :, 0] =  im\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#convert list of pixel values to RGB arrays\n",
    "df['pixels'] = df['pixels'].apply(lambda x: to_rgb1a(np.reshape(np.array(x.split()),(48,48))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35887"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[[[70.0, 70.0, 70.0], [80.0, 80.0, 80.0], [82....</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[[[151.0, 151.0, 151.0], [150.0, 150.0, 150.0]...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[[[231.0, 231.0, 231.0], [212.0, 212.0, 212.0]...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[[[24.0, 24.0, 24.0], [32.0, 32.0, 32.0], [36....</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>[[[4.0, 4.0, 4.0], [0.0, 0.0, 0.0], [0.0, 0.0,...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                             pixels     Usage\n",
       "0        0  [[[70.0, 70.0, 70.0], [80.0, 80.0, 80.0], [82....  Training\n",
       "1        0  [[[151.0, 151.0, 151.0], [150.0, 150.0, 150.0]...  Training\n",
       "2        2  [[[231.0, 231.0, 231.0], [212.0, 212.0, 212.0]...  Training\n",
       "3        4  [[[24.0, 24.0, 24.0], [32.0, 32.0, 32.0], [36....  Training\n",
       "4        6  [[[4.0, 4.0, 4.0], [0.0, 0.0, 0.0], [0.0, 0.0,...  Training"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to add a dimension and vertically stack arrays\n",
    "def paths_to_tensor(arrs):\n",
    "    list_of_tensors = [np.expand_dims(arr, axis = 0) for arr in arrs]\n",
    "    return np.vstack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_input = preprocess_input(paths_to_tensor(df['pixels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 20,024,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg19 import VGG19\n",
    "#initialize VGG19 model\n",
    "VGG19model = VGG19(include_top = False, weights = 'imagenet')\n",
    "VGG19model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.applications.vgg16 import VGG16\n",
    "#initialize VGG16 model\n",
    "VGG16model = VGG16(include_top = False, weights = 'imagenet')\n",
    "VGG16model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 24min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#save bottleneck features for training data\n",
    "VGG16_bottleneck_features_train = VGG16model.predict(img_input[train_indices])\n",
    "np.save('VGG16_bottleneck_features_train.npy', VGG16_bottleneck_features_train) \n",
    "\n",
    "VGG19_bottleneck_features_train = VGG19model.predict(img_input[train_indices])\n",
    "np.save('VGG19_bottleneck_features_train.npy', VGG19_bottleneck_features_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#save VGG16 bottleneck features for validation data\n",
    "VGG16_bottleneck_features_valid = VGG16model.predict(img_input[valid_indices])\n",
    "np.save('VGG16_bottleneck_features_valid.npy', VGG16_bottleneck_features_valid) \n",
    "\n",
    "#load features\n",
    "VGG16_train_data  = np.load('VGG16_bottleneck_features_train.npy')\n",
    "VGG16_valid_data = np.load('VGG16_bottleneck_features_valid.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save VGG19 bottleneck features for validation data\n",
    "VGG19_bottleneck_features_valid = VGG19model.predict(img_input[valid_indices])\n",
    "np.save('VGG19_bottleneck_features_valid.npy', VGG19_bottleneck_features_valid) \n",
    "\n",
    "#load features\n",
    "VGG19_train_data  = np.load('VGG19_bottleneck_features_train.npy')\n",
    "VGG19_valid_data = np.load('VGG19_bottleneck_features_valid.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_9 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 7)                 3591      \n",
      "=================================================================\n",
      "Total params: 266,247\n",
      "Trainable params: 266,247\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "#define model architecture\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=VGG19_train_data.shape[1:]))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22967 samples, validate on 5742 samples\n",
      "Epoch 1/20\n",
      "22900/22967 [============================>.] - ETA: 0s - loss: 10.1110 - acc: 0.3622Epoch 00000: val_loss improved from inf to 9.80936, saving model to C:/Users/Alvin/.keras/models/weights.best.VGG19.face-00-9.81.hdf5\n",
      "22967/22967 [==============================] - 12s - loss: 10.1111 - acc: 0.3622 - val_loss: 9.8094 - val_acc: 0.3797\n",
      "Epoch 2/20\n",
      "22840/22967 [============================>.] - ETA: 0s - loss: 10.0051 - acc: 0.3676Epoch 00001: val_loss did not improve\n",
      "22967/22967 [==============================] - 10s - loss: 10.0018 - acc: 0.3679 - val_loss: 9.9208 - val_acc: 0.3758\n",
      "Epoch 3/20\n",
      "22840/22967 [============================>.] - ETA: 0s - loss: 9.9830 - acc: 0.3708Epoch 00002: val_loss improved from 9.80936 to 9.80165, saving model to C:/Users/Alvin/.keras/models/weights.best.VGG19.face-02-9.80.hdf5\n",
      "22967/22967 [==============================] - 10s - loss: 9.9870 - acc: 0.3705 - val_loss: 9.8016 - val_acc: 0.3812\n",
      "Epoch 4/20\n",
      "22860/22967 [============================>.] - ETA: 0s - loss: 10.0156 - acc: 0.3680Epoch 00003: val_loss did not improve\n",
      "22967/22967 [==============================] - 12s - loss: 10.0138 - acc: 0.3682 - val_loss: 9.8433 - val_acc: 0.3802\n",
      "Epoch 5/20\n",
      "22920/22967 [============================>.] - ETA: 0s - loss: 10.0281 - acc: 0.3678Epoch 00004: val_loss did not improve\n",
      "22967/22967 [==============================] - 11s - loss: 10.0247 - acc: 0.3680 - val_loss: 9.9097 - val_acc: 0.3765\n",
      "Epoch 6/20\n",
      "22880/22967 [============================>.] - ETA: 0s - loss: 10.0066 - acc: 0.3690Epoch 00005: val_loss did not improve\n",
      "22967/22967 [==============================] - 11s - loss: 10.0090 - acc: 0.3688 - val_loss: 9.9064 - val_acc: 0.3751\n",
      "Epoch 7/20\n",
      "22860/22967 [============================>.] - ETA: 0s - loss: 9.9632 - acc: 0.3724Epoch 00006: val_loss did not improve\n",
      "22967/22967 [==============================] - 11s - loss: 9.9614 - acc: 0.3725 - val_loss: 9.8524 - val_acc: 0.3786\n",
      "Epoch 8/20\n",
      "22900/22967 [============================>.] - ETA: 0s - loss: 9.9041 - acc: 0.3748Epoch 00007: val_loss improved from 9.80165 to 9.77661, saving model to C:/Users/Alvin/.keras/models/weights.best.VGG19.face-07-9.78.hdf5\n",
      "22967/22967 [==============================] - 9s - loss: 9.8997 - acc: 0.3751 - val_loss: 9.7766 - val_acc: 0.3814\n",
      "Epoch 9/20\n",
      "22960/22967 [============================>.] - ETA: 0s - loss: 9.9280 - acc: 0.3742Epoch 00008: val_loss did not improve\n",
      "22967/22967 [==============================] - 9s - loss: 9.9277 - acc: 0.3742 - val_loss: 9.8463 - val_acc: 0.3790\n",
      "Epoch 10/20\n",
      "22900/22967 [============================>.] - ETA: 0s - loss: 9.8866 - acc: 0.3770Epoch 00009: val_loss improved from 9.77661 to 9.69483, saving model to C:/Users/Alvin/.keras/models/weights.best.VGG19.face-09-9.69.hdf5\n",
      "22967/22967 [==============================] - 10s - loss: 9.8871 - acc: 0.3770 - val_loss: 9.6948 - val_acc: 0.3880\n",
      "Epoch 11/20\n",
      "22900/22967 [============================>.] - ETA: 0s - loss: 10.0399 - acc: 0.3702Epoch 00010: val_loss did not improve\n",
      "22967/22967 [==============================] - 10s - loss: 10.0402 - acc: 0.3702 - val_loss: 9.9350 - val_acc: 0.3746\n",
      "Epoch 12/20\n",
      "22860/22967 [============================>.] - ETA: 0s - loss: 9.9182 - acc: 0.3748Epoch 00011: val_loss did not improve\n",
      "22967/22967 [==============================] - 10s - loss: 9.9148 - acc: 0.3751 - val_loss: 9.8961 - val_acc: 0.3767\n",
      "Epoch 13/20\n",
      "22900/22967 [============================>.] - ETA: 0s - loss: 9.9625 - acc: 0.3736Epoch 00012: val_loss did not improve\n",
      "22967/22967 [==============================] - 9s - loss: 9.9640 - acc: 0.3735 - val_loss: 10.0486 - val_acc: 0.3696\n",
      "Epoch 14/20\n",
      "22900/22967 [============================>.] - ETA: 0s - loss: 9.9241 - acc: 0.3772Epoch 00013: val_loss did not improve\n",
      "22967/22967 [==============================] - 8s - loss: 9.9253 - acc: 0.3772 - val_loss: 10.2468 - val_acc: 0.3563\n",
      "Epoch 15/20\n",
      "22960/22967 [============================>.] - ETA: 0s - loss: 9.8385 - acc: 0.3820Epoch 00014: val_loss did not improve\n",
      "22967/22967 [==============================] - 9s - loss: 9.8377 - acc: 0.3820 - val_loss: 9.7641 - val_acc: 0.3858\n",
      "Epoch 16/20\n",
      "22920/22967 [============================>.] - ETA: 0s - loss: 9.8612 - acc: 0.3808Epoch 00015: val_loss improved from 9.69483 to 9.69206, saving model to C:/Users/Alvin/.keras/models/weights.best.VGG19.face-15-9.69.hdf5\n",
      "22967/22967 [==============================] - 9s - loss: 9.8586 - acc: 0.3810 - val_loss: 9.6921 - val_acc: 0.3908\n",
      "Epoch 17/20\n",
      "22900/22967 [============================>.] - ETA: 0s - loss: 9.9201 - acc: 0.3770Epoch 00016: val_loss did not improve\n",
      "22967/22967 [==============================] - 9s - loss: 9.9167 - acc: 0.3772 - val_loss: 9.8337 - val_acc: 0.3831\n",
      "Epoch 18/20\n",
      "22840/22967 [============================>.] - ETA: 0s - loss: 9.8358 - acc: 0.3828Epoch 00017: val_loss did not improve\n",
      "22967/22967 [==============================] - 9s - loss: 9.8383 - acc: 0.3827 - val_loss: 9.9801 - val_acc: 0.3758\n",
      "Epoch 19/20\n",
      "22880/22967 [============================>.] - ETA: 0s - loss: 9.9443 - acc: 0.3769Epoch 00018: val_loss did not improve\n",
      "22967/22967 [==============================] - 11s - loss: 9.9403 - acc: 0.3772 - val_loss: 9.9289 - val_acc: 0.3776\n",
      "Epoch 20/20\n",
      "22780/22967 [============================>.] - ETA: 0s - loss: 9.8790 - acc: 0.3807Epoch 00019: val_loss did not improve\n",
      "22967/22967 [==============================] - 10s - loss: 9.8742 - acc: 0.3809 - val_loss: 9.9376 - val_acc: 0.3770\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='C:/Users/Alvin/.keras/models/weights.best.VGG19.face-{epoch:02d}-{val_loss:.2f}.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "model.fit(VGG19_train_data, train_labels,\n",
    "          epochs=20,\n",
    "          batch_size=20,\n",
    "          validation_data=(VGG19_valid_data, valid_labels), callbacks = [checkpointer])\n",
    "model.save_weights('bottleneck_fc_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
