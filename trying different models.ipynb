{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "df = pd.read_excel('fer2013.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import ceil \n",
    "\n",
    "indices = list(range(len(df[df['Usage'] == 'Training'])))\n",
    "np.random.shuffle(indices)\n",
    "train_indices = indices[ceil(len(indices)/5):]\n",
    "valid_indices = indices[:ceil(len(indices)/5)]\n",
    "labels = df.emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "one_hot_labels = keras.utils.to_categorical(df.emotion, num_classes=len(df.emotion.unique()))\n",
    "test_labels = one_hot_labels[~df.index.isin(indices)]\n",
    "train_labels = one_hot_labels[train_indices]\n",
    "valid_labels = one_hot_labels[valid_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_rgb1a(im):\n",
    "    # Convert to RGB\n",
    "    w, h = im.shape\n",
    "    ret = np.empty((w, h, 3), dtype=np.float16)\n",
    "    ret[:, :, 2] =  ret[:, :, 1] =  ret[:, :, 0] =  im\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 23s, sys: 368 ms, total: 1min 23s\n",
      "Wall time: 1min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['pixels'] = df['pixels'].apply(lambda x: to_rgb1a(np.reshape(np.array(x.split()),(48,48))))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def paths_to_tensor(arrs):\n",
    "    list_of_tensors = [np.expand_dims(arr, axis = 0) for arr in arrs]\n",
    "    return np.vstack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_input = preprocess_input(paths_to_tensor(df['pixels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_24 (Conv2D)           (None, 48, 48, 16)        208       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 24, 24, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 24, 24, 32)        2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 12, 12, 64)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 6, 6, 512)         33280     \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_7 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 7)                 3591      \n",
      "=================================================================\n",
      "Total params: 47,415\n",
      "Trainable params: 47,415\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16, kernel_size=2,padding='same', activation='relu', input_shape=img_input[train_indices].shape[1:]))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=64, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22967 samples, validate on 5742 samples\n",
      "Epoch 1/10\n",
      "22960/22967 [============================>.] - ETA: 0s - loss: 1.4001 - acc: 0.4701Epoch 00000: val_loss improved from inf to 1.72918, saving model to C:/Users/Alvin/.keras/models/weights.best.scratch2.face-00-1.73.hdf5\n",
      "22967/22967 [==============================] - 48s - loss: 1.3999 - acc: 0.4702 - val_loss: 1.7292 - val_acc: 0.3553\n",
      "Epoch 2/10\n",
      "22940/22967 [============================>.] - ETA: 0s - loss: 1.3787 - acc: 0.4796Epoch 00001: val_loss improved from 1.72918 to 1.52872, saving model to C:/Users/Alvin/.keras/models/weights.best.scratch2.face-01-1.53.hdf5\n",
      "22967/22967 [==============================] - 48s - loss: 1.3781 - acc: 0.4798 - val_loss: 1.5287 - val_acc: 0.4626\n",
      "Epoch 3/10\n",
      "22960/22967 [============================>.] - ETA: 0s - loss: 1.3833 - acc: 0.4740Epoch 00002: val_loss improved from 1.52872 to 1.48844, saving model to C:/Users/Alvin/.keras/models/weights.best.scratch2.face-02-1.49.hdf5\n",
      "22967/22967 [==============================] - 48s - loss: 1.3831 - acc: 0.4741 - val_loss: 1.4884 - val_acc: 0.4490\n",
      "Epoch 4/10\n",
      "22960/22967 [============================>.] - ETA: 0s - loss: 1.3816 - acc: 0.4819Epoch 00003: val_loss did not improve\n",
      "22967/22967 [==============================] - 49s - loss: 1.3817 - acc: 0.4818 - val_loss: 1.6534 - val_acc: 0.4047\n",
      "Epoch 5/10\n",
      "22960/22967 [============================>.] - ETA: 0s - loss: 1.3868 - acc: 0.4803Epoch 00004: val_loss did not improve\n",
      "22967/22967 [==============================] - 54s - loss: 1.3868 - acc: 0.4803 - val_loss: 1.5193 - val_acc: 0.4073\n",
      "Epoch 6/10\n",
      "22960/22967 [============================>.] - ETA: 0s - loss: 1.3919 - acc: 0.4771Epoch 00005: val_loss did not improve\n",
      "22967/22967 [==============================] - 45s - loss: 1.3918 - acc: 0.4771 - val_loss: 1.6917 - val_acc: 0.4227\n",
      "Epoch 7/10\n",
      "22940/22967 [============================>.] - ETA: 0s - loss: 1.4013 - acc: 0.4691Epoch 00006: val_loss did not improve\n",
      "22967/22967 [==============================] - 51s - loss: 1.4012 - acc: 0.4693 - val_loss: 1.5832 - val_acc: 0.4133\n",
      "Epoch 8/10\n",
      "22960/22967 [============================>.] - ETA: 0s - loss: 1.4055 - acc: 0.4693Epoch 00007: val_loss improved from 1.48844 to 1.42660, saving model to C:/Users/Alvin/.keras/models/weights.best.scratch2.face-07-1.43.hdf5\n",
      "22967/22967 [==============================] - 51s - loss: 1.4056 - acc: 0.4692 - val_loss: 1.4266 - val_acc: 0.4612\n",
      "Epoch 9/10\n",
      "22940/22967 [============================>.] - ETA: 0s - loss: 1.4015 - acc: 0.4707Epoch 00008: val_loss did not improve\n",
      "22967/22967 [==============================] - 44s - loss: 1.4013 - acc: 0.4707 - val_loss: 1.4745 - val_acc: 0.4296\n",
      "Epoch 10/10\n",
      "22960/22967 [============================>.] - ETA: 0s - loss: 1.3998 - acc: 0.4740Epoch 00009: val_loss did not improve\n",
      "22967/22967 [==============================] - 41s - loss: 1.4002 - acc: 0.4739 - val_loss: 1.5318 - val_acc: 0.4145\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='C:/Users/Alvin/.keras/models/weights.best.scratch2.face-{epoch:02d}-{val_loss:.2f}.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "model.fit(img_input[train_indices], train_labels,\n",
    "          epochs=10,\n",
    "          batch_size=20,\n",
    "          validation_data=(img_input[valid_indices], valid_labels), callbacks = [checkpointer])\n",
    "model.save_weights('bottleneck_fc_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_33 (Conv2D)           (None, 48, 48, 8)         104       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 24, 24, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 24, 24, 16)        528       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling (None, 12, 12, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 12, 12, 32)        2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 6, 6, 256)         8448      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_10  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 7)                 1799      \n",
      "=================================================================\n",
      "Total params: 12,959\n",
      "Trainable params: 12,959\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Conv2D(filters=8, kernel_size=2,padding='same', activation='relu', input_shape=img_input[train_indices].shape[1:]))\n",
    "model2.add(MaxPooling2D(pool_size=2))\n",
    "model2.add(Conv2D(filters=16, kernel_size=2, padding='same', activation='relu'))\n",
    "model2.add(MaxPooling2D(pool_size=2))\n",
    "model2.add(Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "model2.add(MaxPooling2D(pool_size=2))\n",
    "model2.add(Dense(256, activation='relu'))\n",
    "model2.add(GlobalAveragePooling2D())\n",
    "model2.add(Dense(7, activation='softmax'))\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22967 samples, validate on 5742 samples\n",
      "Epoch 1/10\n",
      "22960/22967 [============================>.] - ETA: 0s - loss: 1.8424 - acc: 0.2577Epoch 00000: val_loss improved from inf to 1.78292, saving model to C:/Users/Alvin/.keras/models/weights.best.scratch2.face-00-1.78.hdf5\n",
      "22967/22967 [==============================] - 29s - loss: 1.8424 - acc: 0.2576 - val_loss: 1.7829 - val_acc: 0.2816\n",
      "Epoch 2/10\n",
      "22940/22967 [============================>.] - ETA: 0s - loss: 1.6989 - acc: 0.3096Epoch 00001: val_loss improved from 1.78292 to 1.67711, saving model to C:/Users/Alvin/.keras/models/weights.best.scratch2.face-01-1.68.hdf5\n",
      "22967/22967 [==============================] - 29s - loss: 1.6992 - acc: 0.3095 - val_loss: 1.6771 - val_acc: 0.3333\n",
      "Epoch 3/10\n",
      "22940/22967 [============================>.] - ETA: 0s - loss: 1.6450 - acc: 0.3426Epoch 00002: val_loss improved from 1.67711 to 1.66237, saving model to C:/Users/Alvin/.keras/models/weights.best.scratch2.face-02-1.66.hdf5\n",
      "22967/22967 [==============================] - 26s - loss: 1.6450 - acc: 0.3427 - val_loss: 1.6624 - val_acc: 0.3380\n",
      "Epoch 4/10\n",
      "22960/22967 [============================>.] - ETA: 0s - loss: 1.5984 - acc: 0.3686- ETA: 1s - loss: 1.Epoch 00003: val_loss improved from 1.66237 to 1.60207, saving model to C:/Users/Alvin/.keras/models/weights.best.scratch2.face-03-1.60.hdf5\n",
      "22967/22967 [==============================] - 27s - loss: 1.5984 - acc: 0.3686 - val_loss: 1.6021 - val_acc: 0.3757\n",
      "Epoch 5/10\n",
      "22920/22967 [============================>.] - ETA: 0s - loss: 1.5613 - acc: 0.3897- Epoch 00004: val_loss did not improve\n",
      "22967/22967 [==============================] - 22s - loss: 1.5613 - acc: 0.3897 - val_loss: 1.6038 - val_acc: 0.3570\n",
      "Epoch 6/10\n",
      "22920/22967 [============================>.] - ETA: 0s - loss: 1.5307 - acc: 0.4006- ETA: 1Epoch 00005: val_loss improved from 1.60207 to 1.52161, saving model to C:/Users/Alvin/.keras/models/weights.best.scratch2.face-05-1.52.hdf5\n",
      "22967/22967 [==============================] - 22s - loss: 1.5307 - acc: 0.4006 - val_loss: 1.5216 - val_acc: 0.4143\n",
      "Epoch 7/10\n",
      "22960/22967 [============================>.] - ETA: 0s - loss: 1.5025 - acc: 0.4203Epoch 00006: val_loss improved from 1.52161 to 1.51349, saving model to C:/Users/Alvin/.keras/models/weights.best.scratch2.face-06-1.51.hdf5\n",
      "22967/22967 [==============================] - 26s - loss: 1.5025 - acc: 0.4204 - val_loss: 1.5135 - val_acc: 0.4140\n",
      "Epoch 8/10\n",
      "22920/22967 [============================>.] - ETA: 0s - loss: 1.4791 - acc: 0.4277Epoch 00007: val_loss did not improve\n",
      "22967/22967 [==============================] - 29s - loss: 1.4793 - acc: 0.4279 - val_loss: 1.5176 - val_acc: 0.4244\n",
      "Epoch 9/10\n",
      "22960/22967 [============================>.] - ETA: 0s - loss: 1.4565 - acc: 0.4377Epoch 00008: val_loss did not improve\n",
      "22967/22967 [==============================] - 27s - loss: 1.4564 - acc: 0.4377 - val_loss: 1.6449 - val_acc: 0.3957\n",
      "Epoch 10/10\n",
      "22940/22967 [============================>.] - ETA: 0s - loss: 1.4342 - acc: 0.4459Epoch 00009: val_loss improved from 1.51349 to 1.49075, saving model to C:/Users/Alvin/.keras/models/weights.best.scratch2.face-09-1.49.hdf5\n",
      "22967/22967 [==============================] - 24s - loss: 1.4343 - acc: 0.4459 - val_loss: 1.4907 - val_acc: 0.4237\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model2.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='C:/Users/Alvin/.keras/models/weights.best.scratch2.face-{epoch:02d}-{val_loss:.2f}.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "model2.fit(img_input[train_indices], train_labels,\n",
    "          epochs=10,\n",
    "          batch_size=20,\n",
    "          validation_data=(img_input[valid_indices], valid_labels), callbacks = [checkpointer])\n",
    "model2.save_weights('bottleneck_fc_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_39 (Conv2D)           (None, 48, 48, 16)        208       \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 48, 48, 16)        1040      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 24, 24, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 24, 24, 32)        2080      \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 24, 24, 32)        4128      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 12, 12, 64)        8256      \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 12, 12, 64)        16448     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 6, 6, 512)         33280     \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_7 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 7)                 3591      \n",
      "=================================================================\n",
      "Total params: 69,031.0\n",
      "Trainable params: 69,031.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "model3 = Sequential()\n",
    "model3.add(Conv2D(filters=16, kernel_size=2,padding='same', activation='relu', input_shape=img_input[train_indices].shape[1:]))\n",
    "model3.add(Conv2D(filters=16, kernel_size=2, padding='same', activation='relu'))\n",
    "model3.add(MaxPooling2D(pool_size=2))\n",
    "model3.add(Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "model3.add(Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "model3.add(MaxPooling2D(pool_size=2))\n",
    "model3.add(Conv2D(filters=64, kernel_size=2, padding='same', activation='relu'))\n",
    "model3.add(Conv2D(filters=64, kernel_size=2, padding='same', activation='relu'))\n",
    "model3.add(MaxPooling2D(pool_size=2))\n",
    "model3.add(Dense(512, activation='relu'))\n",
    "model3.add(GlobalAveragePooling2D())\n",
    "model3.add(Dense(7, activation='softmax'))\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22967 samples, validate on 5742 samples\n",
      "Epoch 1/10\n",
      "22960/22967 [============================>.] - ETA: 0s - loss: 1.0842 - acc: 0.5887Epoch 00000: val_loss improved from inf to 1.29601, saving model to models/weights.best.scratch2.face-00-1.30.hdf5\n",
      "22967/22967 [==============================] - 74s - loss: 1.0843 - acc: 0.5887 - val_loss: 1.2960 - val_acc: 0.5200\n",
      "Epoch 2/10\n",
      "22960/22967 [============================>.] - ETA: 0s - loss: 1.0539 - acc: 0.5994Epoch 00001: val_loss did not improve\n",
      "22967/22967 [==============================] - 74s - loss: 1.0540 - acc: 0.5993 - val_loss: 1.3098 - val_acc: 0.5232\n",
      "Epoch 3/10\n",
      "22960/22967 [============================>.] - ETA: 0s - loss: 1.0252 - acc: 0.6147Epoch 00002: val_loss did not improve\n",
      "22967/22967 [==============================] - 74s - loss: 1.0254 - acc: 0.6146 - val_loss: 1.3112 - val_acc: 0.5265\n",
      "Epoch 4/10\n",
      "22960/22967 [============================>.] - ETA: 0s - loss: 0.9919 - acc: 0.6239Epoch 00003: val_loss did not improve\n",
      "22967/22967 [==============================] - 74s - loss: 0.9917 - acc: 0.6239 - val_loss: 1.3251 - val_acc: 0.5155\n",
      "Epoch 5/10\n",
      "22960/22967 [============================>.] - ETA: 0s - loss: 0.9526 - acc: 0.6398Epoch 00004: val_loss did not improve\n",
      "22967/22967 [==============================] - 74s - loss: 0.9526 - acc: 0.6399 - val_loss: 1.3016 - val_acc: 0.5362\n",
      "Epoch 6/10\n",
      "22960/22967 [============================>.] - ETA: 0s - loss: 0.9311 - acc: 0.6429Epoch 00005: val_loss did not improve\n",
      "22967/22967 [==============================] - 74s - loss: 0.9309 - acc: 0.6430 - val_loss: 1.4625 - val_acc: 0.5150\n",
      "Epoch 7/10\n",
      "22960/22967 [============================>.] - ETA: 0s - loss: 0.8894 - acc: 0.6628Epoch 00006: val_loss did not improve\n",
      "22967/22967 [==============================] - 74s - loss: 0.8895 - acc: 0.6628 - val_loss: 1.3735 - val_acc: 0.5263\n",
      "Epoch 8/10\n",
      "22960/22967 [============================>.] - ETA: 0s - loss: 0.8615 - acc: 0.6715Epoch 00007: val_loss did not improve\n",
      "22967/22967 [==============================] - 74s - loss: 0.8613 - acc: 0.6716 - val_loss: 1.3972 - val_acc: 0.5228\n",
      "Epoch 9/10\n",
      "22960/22967 [============================>.] - ETA: 0s - loss: 0.8302 - acc: 0.6849Epoch 00008: val_loss did not improve\n",
      "22967/22967 [==============================] - 74s - loss: 0.8303 - acc: 0.6849 - val_loss: 1.3755 - val_acc: 0.5320\n",
      "Epoch 10/10\n",
      "22960/22967 [============================>.] - ETA: 0s - loss: 0.7952 - acc: 0.6984Epoch 00009: val_loss did not improve\n",
      "22967/22967 [==============================] - 74s - loss: 0.7954 - acc: 0.6984 - val_loss: 1.4758 - val_acc: 0.5313\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model3.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='models/weights.best.scratch2.face-{epoch:02d}-{val_loss:.2f}.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "model3.fit(img_input[train_indices], train_labels,\n",
    "          epochs=10,\n",
    "          batch_size=20,\n",
    "          validation_data=(img_input[valid_indices], valid_labels), callbacks = [checkpointer])\n",
    "model3.save_weights('bottleneck_fc_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_78 (Conv2D)           (None, 48, 48, 16)        208       \n",
      "_________________________________________________________________\n",
      "conv2d_79 (Conv2D)           (None, 48, 48, 16)        1040      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling (None, 24, 24, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_80 (Conv2D)           (None, 24, 24, 32)        2080      \n",
      "_________________________________________________________________\n",
      "conv2d_81 (Conv2D)           (None, 24, 24, 32)        4128      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_82 (Conv2D)           (None, 12, 12, 64)        8256      \n",
      "_________________________________________________________________\n",
      "conv2d_83 (Conv2D)           (None, 12, 12, 64)        16448     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 6, 6, 128)         8320      \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 6, 6, 128)         16512     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_13  (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 57,895.0\n",
      "Trainable params: 57,895.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "model4 = Sequential()\n",
    "model4.add(Conv2D(filters=16, kernel_size=2,padding='same', activation='relu', input_shape=img_input[train_indices].shape[1:]))\n",
    "model4.add(Conv2D(filters=16, kernel_size=2, padding='same', activation='relu'))\n",
    "model4.add(MaxPooling2D(pool_size=2))\n",
    "model4.add(Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "model4.add(Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "model4.add(MaxPooling2D(pool_size=2))\n",
    "model4.add(Conv2D(filters=64, kernel_size=2, padding='same', activation='relu'))\n",
    "model4.add(Conv2D(filters=64, kernel_size=2, padding='same', activation='relu'))\n",
    "model4.add(MaxPooling2D(pool_size=2))\n",
    "model4.add(Dense(128, activation='relu'))\n",
    "model4.add(Dense(128, activation='relu'))\n",
    "model4.add(Dropout(0.5))\n",
    "model4.add(GlobalAveragePooling2D())\n",
    "model4.add(Dense(7, activation='softmax'))\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22967 samples, validate on 5742 samples\n",
      "Epoch 1/10\n",
      "22960/22967 [============================>.] - ETA: 0s - loss: 1.7929 - acc: 0.2561Epoch 00000: val_loss improved from inf to 1.74466, saving model to models/weights.best.scratch2.face-00-1.74.hdf5\n",
      "22967/22967 [==============================] - 74s - loss: 1.7929 - acc: 0.2561 - val_loss: 1.7447 - val_acc: 0.2790\n",
      "Epoch 2/10\n",
      "22960/22967 [============================>.] - ETA: 0s - loss: 1.6619 - acc: 0.3277Epoch 00001: val_loss improved from 1.74466 to 1.56024, saving model to models/weights.best.scratch2.face-01-1.56.hdf5\n",
      "22967/22967 [==============================] - 73s - loss: 1.6618 - acc: 0.3277 - val_loss: 1.5602 - val_acc: 0.3690\n",
      "Epoch 3/10\n",
      "22960/22967 [============================>.] - ETA: 0s - loss: 1.5054 - acc: 0.4094Epoch 00002: val_loss improved from 1.56024 to 1.43341, saving model to models/weights.best.scratch2.face-02-1.43.hdf5\n",
      "22967/22967 [==============================] - 73s - loss: 1.5055 - acc: 0.4094 - val_loss: 1.4334 - val_acc: 0.4396\n",
      "Epoch 4/10\n",
      "22960/22967 [============================>.] - ETA: 0s - loss: 1.4142 - acc: 0.4553Epoch 00003: val_loss improved from 1.43341 to 1.37785, saving model to models/weights.best.scratch2.face-03-1.38.hdf5\n",
      "22967/22967 [==============================] - 73s - loss: 1.4143 - acc: 0.4553 - val_loss: 1.3778 - val_acc: 0.4671\n",
      "Epoch 5/10\n",
      "22960/22967 [============================>.] - ETA: 0s - loss: 1.3409 - acc: 0.4873Epoch 00004: val_loss improved from 1.37785 to 1.35423, saving model to models/weights.best.scratch2.face-04-1.35.hdf5\n",
      "22967/22967 [==============================] - 73s - loss: 1.3410 - acc: 0.4873 - val_loss: 1.3542 - val_acc: 0.4739\n",
      "Epoch 6/10\n",
      "22960/22967 [============================>.] - ETA: 0s - loss: 1.2796 - acc: 0.5125Epoch 00005: val_loss improved from 1.35423 to 1.32597, saving model to models/weights.best.scratch2.face-05-1.33.hdf5\n",
      "22967/22967 [==============================] - 73s - loss: 1.2795 - acc: 0.5126 - val_loss: 1.3260 - val_acc: 0.4890\n",
      "Epoch 7/10\n",
      "22960/22967 [============================>.] - ETA: 0s - loss: 1.2360 - acc: 0.5291Epoch 00006: val_loss improved from 1.32597 to 1.30317, saving model to models/weights.best.scratch2.face-06-1.30.hdf5\n",
      "22967/22967 [==============================] - 73s - loss: 1.2359 - acc: 0.5292 - val_loss: 1.3032 - val_acc: 0.5031\n",
      "Epoch 8/10\n",
      "22960/22967 [============================>.] - ETA: 0s - loss: 1.1992 - acc: 0.5419Epoch 00007: val_loss improved from 1.30317 to 1.27239, saving model to models/weights.best.scratch2.face-07-1.27.hdf5\n",
      "22967/22967 [==============================] - 73s - loss: 1.1997 - acc: 0.5418 - val_loss: 1.2724 - val_acc: 0.5131\n",
      "Epoch 9/10\n",
      "22960/22967 [============================>.] - ETA: 0s - loss: 1.1609 - acc: 0.5557Epoch 00008: val_loss improved from 1.27239 to 1.26856, saving model to models/weights.best.scratch2.face-08-1.27.hdf5\n",
      "22967/22967 [==============================] - 73s - loss: 1.1610 - acc: 0.5556 - val_loss: 1.2686 - val_acc: 0.5044\n",
      "Epoch 10/10\n",
      "22960/22967 [============================>.] - ETA: 0s - loss: 1.1307 - acc: 0.5688Epoch 00009: val_loss did not improve\n",
      "22967/22967 [==============================] - 73s - loss: 1.1307 - acc: 0.5687 - val_loss: 1.3494 - val_acc: 0.5052\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model4.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='models/weights.best.scratch2.face-{epoch:02d}-{val_loss:.2f}.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "model4.fit(img_input[train_indices], train_labels,\n",
    "          epochs=10,\n",
    "          batch_size=20,\n",
    "          validation_data=(img_input[valid_indices], valid_labels), callbacks = [checkpointer])\n",
    "model4.save_weights('bottleneck_fc_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_121 (Conv2D)          (None, 48, 48, 16)        208       \n",
      "_________________________________________________________________\n",
      "conv2d_122 (Conv2D)          (None, 48, 48, 16)        1040      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_55 (MaxPooling (None, 24, 24, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_123 (Conv2D)          (None, 24, 24, 32)        2080      \n",
      "_________________________________________________________________\n",
      "conv2d_124 (Conv2D)          (None, 24, 24, 32)        4128      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_56 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_125 (Conv2D)          (None, 12, 12, 64)        8256      \n",
      "_________________________________________________________________\n",
      "conv2d_126 (Conv2D)          (None, 12, 12, 64)        16448     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_57 (MaxPooling (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 6, 6, 128)         8320      \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 6, 6, 256)         33024     \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_19  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 7)                 1799      \n",
      "=================================================================\n",
      "Total params: 75,303.0\n",
      "Trainable params: 75,303.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "model5 = Sequential()\n",
    "model5.add(Conv2D(filters=16, kernel_size=2,padding='same', activation='relu', input_shape=img_input[train_indices].shape[1:]))\n",
    "model5.add(Conv2D(filters=16, kernel_size=2, padding='same', activation='relu'))\n",
    "model5.add(MaxPooling2D(pool_size=2))\n",
    "model5.add(Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "model5.add(Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "model5.add(MaxPooling2D(pool_size=2))\n",
    "model5.add(Conv2D(filters=64, kernel_size=2, padding='same', activation='relu'))\n",
    "model5.add(Conv2D(filters=64, kernel_size=2, padding='same', activation='relu'))\n",
    "model5.add(MaxPooling2D(pool_size=2))\n",
    "model5.add(Dense(128, activation='relu'))\n",
    "model5.add(Dense(256, activation='relu'))\n",
    "model5.add(GlobalAveragePooling2D())\n",
    "#model5.add(Dropout(0.5))\n",
    "model5.add(Dense(7, activation='softmax'))\n",
    "model5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22967 samples, validate on 5742 samples\n",
      "Epoch 1/10\n",
      "22960/22967 [============================>.] - ETA: 0s - loss: 1.7849 - acc: 0.2619Epoch 00000: val_loss improved from inf to 1.75011, saving model to models/weights.best.scratch2.face-00-1.75.hdf5\n",
      "22967/22967 [==============================] - 75s - loss: 1.7848 - acc: 0.2619 - val_loss: 1.7501 - val_acc: 0.2825\n",
      "Epoch 2/10\n",
      "22960/22967 [============================>.] - ETA: 0s - loss: 1.6264 - acc: 0.3464Epoch 00001: val_loss improved from 1.75011 to 1.52496, saving model to models/weights.best.scratch2.face-01-1.52.hdf5\n",
      "22967/22967 [==============================] - 74s - loss: 1.6262 - acc: 0.3465 - val_loss: 1.5250 - val_acc: 0.3793\n",
      "Epoch 3/10\n",
      "22960/22967 [============================>.] - ETA: 0s - loss: 1.4592 - acc: 0.4279Epoch 00002: val_loss improved from 1.52496 to 1.49865, saving model to models/weights.best.scratch2.face-02-1.50.hdf5\n",
      "22967/22967 [==============================] - 74s - loss: 1.4592 - acc: 0.4279 - val_loss: 1.4986 - val_acc: 0.4258\n",
      "Epoch 4/10\n",
      "22960/22967 [============================>.] - ETA: 0s - loss: 1.3446 - acc: 0.4838Epoch 00003: val_loss improved from 1.49865 to 1.35062, saving model to models/weights.best.scratch2.face-03-1.35.hdf5\n",
      "22967/22967 [==============================] - 74s - loss: 1.3445 - acc: 0.4838 - val_loss: 1.3506 - val_acc: 0.4794\n",
      "Epoch 5/10\n",
      "22960/22967 [============================>.] - ETA: 0s - loss: 1.2685 - acc: 0.5146Epoch 00004: val_loss improved from 1.35062 to 1.30074, saving model to models/weights.best.scratch2.face-04-1.30.hdf5\n",
      "22967/22967 [==============================] - 74s - loss: 1.2684 - acc: 0.5146 - val_loss: 1.3007 - val_acc: 0.4955\n",
      "Epoch 6/10\n",
      "22960/22967 [============================>.] - ETA: 0s - loss: 1.2091 - acc: 0.5396Epoch 00005: val_loss improved from 1.30074 to 1.27371, saving model to models/weights.best.scratch2.face-05-1.27.hdf5\n",
      "22967/22967 [==============================] - 74s - loss: 1.2092 - acc: 0.5396 - val_loss: 1.2737 - val_acc: 0.5164\n",
      "Epoch 7/10\n",
      "22960/22967 [============================>.] - ETA: 0s - loss: 1.1636 - acc: 0.5561Epoch 00006: val_loss did not improve\n",
      "22967/22967 [==============================] - 74s - loss: 1.1637 - acc: 0.5560 - val_loss: 1.2786 - val_acc: 0.5216\n",
      "Epoch 8/10\n",
      "22960/22967 [============================>.] - ETA: 0s - loss: 1.1130 - acc: 0.5750Epoch 00007: val_loss improved from 1.27371 to 1.25551, saving model to models/weights.best.scratch2.face-07-1.26.hdf5\n",
      "22967/22967 [==============================] - 74s - loss: 1.1130 - acc: 0.5750 - val_loss: 1.2555 - val_acc: 0.5270\n",
      "Epoch 9/10\n",
      "22960/22967 [============================>.] - ETA: 0s - loss: 1.0707 - acc: 0.5935Epoch 00008: val_loss did not improve\n",
      "22967/22967 [==============================] - 74s - loss: 1.0710 - acc: 0.5933 - val_loss: 1.2935 - val_acc: 0.5204\n",
      "Epoch 10/10\n",
      "22960/22967 [============================>.] - ETA: 0s - loss: 1.0373 - acc: 0.6073Epoch 00009: val_loss did not improve\n",
      "22967/22967 [==============================] - 74s - loss: 1.0372 - acc: 0.6072 - val_loss: 1.3247 - val_acc: 0.5204\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model5.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='models/weights.best.scratch2.face-{epoch:02d}-{val_loss:.2f}.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "model5.fit(img_input[train_indices], train_labels,\n",
    "          epochs=10,\n",
    "          batch_size=20,\n",
    "          validation_data=(img_input[valid_indices], valid_labels), callbacks = [checkpointer])\n",
    "model5.save_weights('bottleneck_fc_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
